# Core libraries
torch
scipy
numpy
packaging
protobuf
jsonlines
fire
termcolor
einops
jupyter

# Transformers & finetuning
transformers==4.36.2
tokenizers>=0.13.3
sentencepiece
datasets
accelerate
peft==0.7.1
bitsandbytes>=0.41.1
deepspeed
evaluate>=0.4.0

# Sampling & eval
alpaca-eval
openai>=1.0.0
tiktoken
rouge_score
nltk
langdetect
immutabledict

# Visualization & logging
tensorboard
wandb
gradio
openpyxl
flask

# Model fine-tuning extras
vllm
flash-attn
auto-gptq

# For LESS
traker[fast]==0.1.3

# Optional: sentence embeddings
sentence-transformers
scikit-learn
