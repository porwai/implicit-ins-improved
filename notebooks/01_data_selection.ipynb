{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1fccb55-0c9f-49b8-9b54-e06d90e0b092",
   "metadata": {},
   "source": [
    "# ðŸ“Š 01_data_selection.ipynb â€” Data Selection Pipeline\n",
    "\n",
    "This notebook prepares the dataset for our instruction tuning experiments by applying **active example selection** to the OpenMathInstruct-1 dataset. Inspired by the LESS paper (Zhang et al., 2024), we aim to test whether **strategically selected examples** can improve instruction-following performance more efficiently than random sampling.\n",
    "\n",
    "## ðŸ”§ What this notebook does:\n",
    "\n",
    "1. **Load** a 10,000-example subset of the OpenMathInstruct-1 dataset\n",
    "2. **Generate sentence embeddings** for the instructions using `MiniLM`\n",
    "3. **Select 1,000 examples** using **KMeans clustering** to maximize diversity\n",
    "4. **Also sample 1,000 random examples** as a baseline\n",
    "5. **Save all outputs** to the `data/` folder for training and evaluation\n",
    "\n",
    "## ðŸ—‚ Outputs:\n",
    "\n",
    "| File | Description |\n",
    "|------|-------------|\n",
    "| `data/openmath_full.json` | All 10K instruction-response pairs |\n",
    "| `data/openmath_embeddings.npy` | Vector embeddings of instructions |\n",
    "| `data/openmath_selected_1k.json` | 1K clustered examples (smart selection) |\n",
    "| `data/openmath_random_1k.json` | 1K random examples (baseline) |\n",
    "\n",
    "These datasets will be used to train separate models and evaluate instruction-following quality using AlpacaEval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccae6d57-503a-43ce-906b-a7ac3a3a65ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only Run if Do not have env set up\n",
    "!pip install datasets sentence-transformers scikit-learn tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e896baae-8c5a-4c11-b65d-f1908eef4426",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23769c4-f839-4448-8727-cccba9527c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import json\n",
    "import os\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# Load first 10k examples (adjust as needed)\n",
    "dataset = load_dataset(\"OpenMathInstruct/OpenMathInstruct-1\", split=\"train\")\n",
    "dataset = dataset.select(range(10000))\n",
    "\n",
    "# Format as instruction-response pairs\n",
    "examples = [{\"instruction\": ex[\"instruction\"], \"response\": ex[\"response\"]} for ex in dataset]\n",
    "\n",
    "# Save full subset\n",
    "with open(\"data/openmath_full.json\", \"w\") as f:\n",
    "    json.dump(examples, f, indent=2)\n",
    "\n",
    "print(f\"âœ… Saved {len(examples)} examples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa15f77-709c-46ae-94c6-c779f567de19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Get instruction texts\n",
    "texts = [ex[\"instruction\"] for ex in examples]\n",
    "\n",
    "# Embed instructions\n",
    "embeddings = model.encode(texts, batch_size=64, show_progress_bar=True)\n",
    "\n",
    "# Save embeddings\n",
    "np.save(\"data/openmath_embeddings.npy\", embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfc3b67-4ca0-474f-a9b1-63235decf532",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Cluster into 1000 groups\n",
    "k = 1000\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "labels = kmeans.fit_predict(embeddings)\n",
    "\n",
    "# Get example closest to each centroid\n",
    "centers = kmeans.cluster_centers_\n",
    "distances = cdist(centers, embeddings)\n",
    "closest_idxs = distances.argmin(axis=1)\n",
    "\n",
    "# Select final training examples\n",
    "selected_examples = [examples[i] for i in closest_idxs]\n",
    "\n",
    "# Save selected examples\n",
    "with open(\"data/openmath_selected_1k.json\", \"w\") as f:\n",
    "    json.dump(selected_examples, f, indent=2)\n",
    "\n",
    "print(\"âœ… Saved data/openmath_selected_1k.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337159a2-d5bb-4438-aa45-65528f6e6087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "random_idxs = random.sample(range(len(examples)), 1000)\n",
    "random_1k = [examples[i] for i in random_idxs]\n",
    "\n",
    "with open(\"data/openmath_random_1k.json\", \"w\") as f:\n",
    "    json.dump(random_1k, f, indent=2)\n",
    "\n",
    "print(\"âœ… Saved data/openmath_random_1k.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cos-484-final)",
   "language": "python",
   "name": "cos-484-final"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
